# Amazon S3 (Simple Storage Service)

Amazon S3 is a service that allows users to store and retrieve any amount of data at any time, from anywhere on the web. It is designed to provide 99.999999999% durability and scales past trillions of objects worldwide. Here’s a brief overview of the key features and concepts:

## Buckets

Buckets are containers for objects (files) stored in Amazon S3. They must have a globally unique name and are defined at the region level.

### Bucket Naming Conventions:
- No uppercase letters or underscores
- Length between 3-63 characters
- Must not resemble an IP address
- Must start with a lowercase letter or number
- Must not start with the prefix `xn--`
- Must not end with the suffix `-s3alias`

## Objects

Objects are the fundamental entities stored in Amazon S3, consisting of data and metadata.

### Key Components:
- **Key**: A unique identifier for an object within a bucket (composed of a prefix and object name). For example, `s3://my-bucket/my_folder1/another_folder/my_file.txt`.
- **Metadata**: A set of name-value pairs that describe the object.
- **Tags**: Up to 10 Unicode key-value pairs for organizing and managing access to objects.
- **Version ID**: A unique identifier for each version of an object if versioning is enabled.

## Versioning

Versioning is a means of keeping multiple variants of an object in the same bucket. It is enabled at the bucket level.

- **Enabled at the bucket level**.
- Allows tracking changes over time.
- Each overwrite creates a new version (e.g., version 1, 2, 3).

## Replication

Amazon S3 supports replication of objects across different regions (Cross-Region Replication - CRR) or within the same region (Same-Region Replication - SRR). Replication requires enabling versioning on both the source and destination buckets.

### Key Points:
- **Cross-Region Replication (CRR)**: Replicates objects to a bucket in another region.
- **Same-Region Replication (SRR)**: Replicates objects to a bucket in the same region.
- **IAM Permissions**: Proper permissions must be configured.
- **Asynchronous Process**: Replication is not instant.
- **Replication of Deletes**: Optionally replicate delete markers but not deletions with version IDs to avoid malicious deletes.
- **Replication Scope**: Only new objects are replicated unless using S3 Batch Replication for existing objects.

## Storage Classes

Amazon S3 offers various storage classes designed for different use cases:

- **S3 Standard**: General-purpose storage with high durability and availability.
- **S3 Standard-Infrequent Access (IA)**: For data that is accessed less frequently but requires rapid access when needed.
- **S3 One Zone-Infrequent Access**: For infrequently accessed data stored in a single availability zone.
- **S3 Glacier Instant Retrieval**: For long-term archival with instant retrieval.
- **S3 Glacier Flexible Retrieval**: Low-cost archive storage with flexible retrieval options.
- **S3 Glacier Deep Archive**: Lowest cost storage for data that is rarely accessed.
- **S3 Intelligent-Tiering**: Automatically moves data between two access tiers when access patterns change.

### Lifecycle Policies

Lifecycle policies can be used to automatically transition objects between different storage classes or to delete objects after a certain period. We can set the policy to change the type after a specific number of days separately for current and non-current versions and also to delete files after particular days.

### Event Notifications

We can set event notifications for various events such as object creation, object deletion, etc. These notifications can be forwarded to other services like SQS, SNS, and Lambda functions. Additionally, Amazon EventBridge can be turned on to forward these events to other 18 services.

### S3 Select

S3 Select performs filtering on the server-side, reducing the amount of data transferred to the user and then filtered.

### Object Metadata and Tags

We can attach metadata and tags to S3 objects. While these cannot be used to filter the data directly based on metadata and tags, we can maintain a separate database for such filtering.

### Amazon S3 – Object Encryption

#### Server-Side Encryption (SSE)
- **Encryption using keys handled, managed, and owned by AWS**
- Object is encrypted server-side
- **Encryption type:** AES-256
- **Header:** `x-amz-server-side-encryption: AES256`
- Enabled by default for new buckets & new objects

#### Server-Side Encryption with KMS Keys stored in AWS KMS (SSE-KMS)
- **Encryption using keys handled and managed by AWS KMS (Key Management Service)**
- **Advantages:** User control + audit key usage using CloudTrail
- Object is encrypted server-side
- **Header:** `x-amz-server-side-encryption: aws:kms`
- **Considerations:**
  - Impact on KMS limits
  - Calls `GenerateDataKey` KMS API during upload
  - Calls `Decrypt` KMS API during download
  - Counts towards the KMS quota per second (5500, 10000, 30000 req/s based on region)

#### Server-Side Encryption with Customer-Provided Keys (SSE-C)
- **Encryption using keys fully managed by the customer outside of AWS**
- Amazon S3 does **NOT** store the encryption key you provide
- **Requirements:**
  - HTTPS must be used
  - Encryption key must be provided in HTTP headers for every HTTP request made

#### Client-Side Encryption

Encryption is managed client-side before uploading the data to Amazon S3.

### MFA (Multi-Factor Authentication)

Multi-Factor Authentication (MFA) forces users to generate a code on a device (usually a mobile phone or hardware) before performing important operations on S3.

#### MFA Requirements
- **Required for:**
  - Permanently deleting an object version
  - Suspending Versioning on the bucket
- **Not required for:**
  - Enabling Versioning
  - Listing deleted versions

#### Additional Information
- **MFA Hardware Device:**
  - To use MFA Delete, Versioning must be enabled on the bucket.
  - Only the bucket owner (root account) can enable/disable MFA Delete.

### S3 Bucket Logging

For audit purposes, log all access to S3 buckets. Any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket. The data can be analyzed using data analysis tools. Note that the target logging bucket must be in the same AWS region.

### Access Points

Access Points simplify security management for S3 Buckets. 
![[Pasted image 20240718221440.png]]
#### Features
- Each Access Point has its own DNS name (Internet Origin or VPC Origin).
- Each Access Point has an access point policy (similar to a bucket policy) for managing security at scale.
- Access Points can be defined to be accessible only from within a VPC.

#### VPC Endpoint
- You must create a VPC Endpoint (Gateway or Interface Endpoint) to access the Access Point.
- The VPC Endpoint Policy must allow access to the target bucket and Access Point.

### AWS Lambda Functions

Use AWS Lambda Functions to change the object before it is retrieved by the caller application. Only one S3 bucket is needed, on top of which we create S3 Access Point and S3 Object Lambda Access Points.
![[Pasted image 20240718221505.png]]
#### Use Cases
- Redacting personally identifiable information for analytics or non-production environments.
- Converting across data formats, such as converting XML to JSON.
- Resizing and watermarking images on the fly using caller-specific details, such as the user who requested the object.